{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Json to Jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "with open('10000dataset.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Open a new file for JSONL output\n",
    "with open('output.jsonl', 'w') as f:\n",
    "    for item in data:\n",
    "        # Write each item as a JSON string on a new line\n",
    "        f.write(json.dumps(item) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling Jsonl Randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Read the JSONL file\n",
    "with open('10000dataset.jsonl', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Shuffle the lines randomly\n",
    "random.shuffle(lines)\n",
    "\n",
    "# Write the shuffled lines to a new JSONL file\n",
    "with open('shuffled_output.jsonl', 'w') as f:\n",
    "    f.writelines(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Input to string from dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete! Saved to 'test.jsonl'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# File paths\n",
    "input_file = 'test1.jsonl'  # Replace with your input JSONL file\n",
    "output_file = 'test.jsonl'  # Replace with your desired output JSONL file\n",
    "\n",
    "# Process the JSONL file\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "    for line in infile:\n",
    "        # Parse each line as JSON\n",
    "        data = json.loads(line.strip())\n",
    "        \n",
    "        # Convert the 'input' dictionary to a JSON string if it's a dictionary\n",
    "        if isinstance(data.get(\"input\"), dict):\n",
    "            data[\"input\"] = json.dumps(data[\"input\"])\n",
    "        \n",
    "        # Write the modified line back to the output file\n",
    "        outfile.write(json.dumps(data) + '\\n')\n",
    "\n",
    "print(f\"Conversion complete! Saved to '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to Convert Data to Llama-3.1 Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted dataset saved to train.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# File paths\n",
    "input_file = \"train1.jsonl\"  # Your raw dataset file\n",
    "output_file = \"train.jsonl\"  # Output file in Llama-3.1 format\n",
    "\n",
    "def convert_to_llama3_format(input_file, output_file):\n",
    "    with open(input_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            try:\n",
    "                # Parse the current line as JSON\n",
    "                data = json.loads(line.strip())\n",
    "                \n",
    "                # Deserialize the input field\n",
    "                user_input_dict = json.loads(data[\"input\"])\n",
    "                \n",
    "                # Extract values with defaults for missing fields\n",
    "                token = user_input_dict.get(\"token\", \"unknown\")\n",
    "                category = user_input_dict.get(\"category\", \"unknown\")\n",
    "                market_scenario = user_input_dict.get(\"market_scenario\", \"unknown\")\n",
    "                twitter_handle = user_input_dict.get(\"twitter_handle\", user_input_dict.get(\"handle\", \"unknown\"))\n",
    "                tone = user_input_dict.get(\"tone\", \"unknown\")\n",
    "                \n",
    "                # Handle metrics or direct fields like \"market_cap\", \"price\", etc.\n",
    "                metrics = user_input_dict.get(\"metrics\", {})\n",
    "                market_cap = user_input_dict.get(\"market_cap\", metrics.get(\"market cap\", \"unknown\"))\n",
    "                price = user_input_dict.get(\"price\", metrics.get(\"price\", \"unknown\"))\n",
    "                price_change = user_input_dict.get(\"price_change\", \"unknown\")\n",
    "                volume = user_input_dict.get(\"volume\", metrics.get(\"volume\", \"unknown\"))\n",
    "                volume_change = user_input_dict.get(\"volume_change\", \"unknown\")\n",
    "                \n",
    "                # Construct user input string\n",
    "                user_input = (\n",
    "                    f\"Token: {token}, \"\n",
    "                    f\"Category: {category}, \"\n",
    "                    f\"Market Scenario: {market_scenario}, \"\n",
    "                    f\"Metrics: Market Cap {market_cap}, Price {price}, \"\n",
    "                    f\"Price Change {price_change}, Volume {volume}, Volume Change {volume_change}, \"\n",
    "                    f\"Twitter Handle: {twitter_handle}, \"\n",
    "                    f\"Tone: {tone}\"\n",
    "                )\n",
    "                \n",
    "                # Get the assistant's output\n",
    "                assistant_output = data[\"output\"]\n",
    "                \n",
    "                # Format into Llama-3.1 style\n",
    "                formatted_conversation = (\n",
    "                    \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\"\n",
    "                    f\"{user_input}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "                    f\"{assistant_output}<|eot_id|>\\n\"\n",
    "                )\n",
    "                \n",
    "                # Write to output file\n",
    "                outfile.write(formatted_conversation)\n",
    "            \n",
    "            except Exception as e:\n",
    "                # Log any issues with processing specific lines\n",
    "                print(f\"Error processing line: {line.strip()}\\nError: {e}\")\n",
    "\n",
    "convert_to_llama3_format(input_file, output_file)\n",
    "print(f\"Formatted dataset saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
